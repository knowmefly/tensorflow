{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-d4dc4a344163>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Iter0,Testing Accuracy0.8292\n",
      "Iter1,Testing Accuracy0.8705\n",
      "Iter2,Testing Accuracy0.8809\n",
      "Iter3,Testing Accuracy0.8885\n",
      "Iter4,Testing Accuracy0.8946\n",
      "Iter5,Testing Accuracy0.8976\n",
      "Iter6,Testing Accuracy0.8989\n",
      "Iter7,Testing Accuracy0.9014\n",
      "Iter8,Testing Accuracy0.9035\n",
      "Iter9,Testing Accuracy0.9054\n",
      "Iter10,Testing Accuracy0.907\n",
      "Iter11,Testing Accuracy0.9071\n",
      "Iter12,Testing Accuracy0.9087\n",
      "Iter13,Testing Accuracy0.9098\n",
      "Iter14,Testing Accuracy0.9103\n",
      "Iter15,Testing Accuracy0.9104\n",
      "Iter16,Testing Accuracy0.9114\n",
      "Iter17,Testing Accuracy0.9129\n",
      "Iter18,Testing Accuracy0.9127\n",
      "Iter19,Testing Accuracy0.9129\n",
      "Iter20,Testing Accuracy0.9138\n",
      "Iter21,Testing Accuracy0.9143\n",
      "Iter22,Testing Accuracy0.9148\n",
      "Iter23,Testing Accuracy0.9155\n",
      "Iter24,Testing Accuracy0.9154\n",
      "Iter25,Testing Accuracy0.9162\n",
      "Iter26,Testing Accuracy0.917\n",
      "Iter27,Testing Accuracy0.9172\n",
      "Iter28,Testing Accuracy0.9177\n",
      "Iter29,Testing Accuracy0.9174\n",
      "Iter30,Testing Accuracy0.9183\n",
      "Iter31,Testing Accuracy0.9181\n",
      "Iter32,Testing Accuracy0.9181\n",
      "Iter33,Testing Accuracy0.9181\n",
      "Iter34,Testing Accuracy0.918\n",
      "Iter35,Testing Accuracy0.9189\n",
      "Iter36,Testing Accuracy0.919\n",
      "Iter37,Testing Accuracy0.9188\n",
      "Iter38,Testing Accuracy0.9195\n",
      "Iter39,Testing Accuracy0.9196\n",
      "Iter40,Testing Accuracy0.9194\n",
      "Iter41,Testing Accuracy0.9191\n",
      "Iter42,Testing Accuracy0.9205\n",
      "Iter43,Testing Accuracy0.9209\n",
      "Iter44,Testing Accuracy0.9203\n",
      "Iter45,Testing Accuracy0.9208\n",
      "Iter46,Testing Accuracy0.9211\n",
      "Iter47,Testing Accuracy0.9213\n",
      "Iter48,Testing Accuracy0.921\n",
      "Iter49,Testing Accuracy0.921\n",
      "Iter50,Testing Accuracy0.9216\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data\",one_hot=True)\n",
    "\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#参数摘要\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)  \n",
    "        tf.summary.scalar('mean',mean) #平均值\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "            tf.summary.scalar('stddev',stddev) #标准差\n",
    "            tf.summary.scalar('max',tf.reduce_max(var)) #最大值\n",
    "            tf.summary.scalar('min',tf.reduce_min(var))  #最小值\n",
    "            tf.summary.histogram('histogram',var)  #直方图\n",
    "\n",
    "#输入\n",
    "with tf.name_scope(\"input\"):\n",
    "    x = tf.placeholder(tf.float32,[None,784], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.float32,[None,10], name=\"y_input\")\n",
    "\n",
    "#权值和偏置值\n",
    "with tf.name_scope(\"layer\"):\n",
    "    with tf.name_scope(\"W\"):\n",
    "        W = tf.Variable(tf.zeros([784,10]))\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope(\"b\"):\n",
    "        b = tf.Variable(tf.zeros([10]))\n",
    "        variable_summaries(b)\n",
    "\n",
    "#预测\n",
    "with tf.name_scope(\"prediction\"):\n",
    "    prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "#损失函数\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "#随机梯度下降优化\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "#比较判断是否正确\n",
    "    with tf.name_scope(\"correct_prediction\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "        \n",
    "#合并summary\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(\"log/2/\", sess.graph)\n",
    "    for epoch in range(51):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            summary, _ = sess.run([merged,train_step],feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        writer.add_summary(summary,epoch)\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Accuracy\" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
