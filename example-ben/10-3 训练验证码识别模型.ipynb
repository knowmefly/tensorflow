{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "from PIL import Image\n",
    "from nets import nets_factory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同字符数量\n",
    "CHAR_SET_LEN = 10\n",
    "# 图片高度\n",
    "IMAGE_HEIGHT = 60 \n",
    "# 图片宽度\n",
    "IMAGE_WIDTH = 160  \n",
    "# 批次\n",
    "BATCH_SIZE = 25\n",
    "# tfrecord文件存放路径\n",
    "TFRECORD_FILE = \"images/captcha_tfrecord/train.tfrecords\"\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224])  \n",
    "y0 = tf.placeholder(tf.float32, [None]) \n",
    "y1 = tf.placeholder(tf.float32, [None]) \n",
    "y2 = tf.placeholder(tf.float32, [None]) \n",
    "y3 = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "lr = tf.Variable(0.003, dtype=tf.float32)\n",
    "\n",
    "# 从tfrecord读出数据\n",
    "def read_and_decode(filename):\n",
    "    # 根据文件名生成一个队列\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "    reader = tf.TFRecordReader()\n",
    "    # 返回文件名和文件\n",
    "    _, serialized_example = reader.read(filename_queue)   \n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={\n",
    "                                           'image' : tf.FixedLenFeature([], tf.string),\n",
    "                                           'label0': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label1': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label2': tf.FixedLenFeature([], tf.int64),\n",
    "                                           'label3': tf.FixedLenFeature([], tf.int64),\n",
    "                                       })\n",
    "    # 获取图片数据\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    # tf.train.shuffle_batch必须确定shape\n",
    "    image = tf.reshape(image, [224, 224])\n",
    "    # 图片预处理\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    # 获取label\n",
    "    label0 = tf.cast(features['label0'], tf.int32)\n",
    "    label1 = tf.cast(features['label1'], tf.int32)\n",
    "    label2 = tf.cast(features['label2'], tf.int32)\n",
    "    label3 = tf.cast(features['label3'], tf.int32)\n",
    "\n",
    "    return image, label0, label1, label2, label3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-fd51b462155d>:24: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-fd51b462155d>:25: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-3-d2a869113561>:7: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "WARNING:tensorflow:From <ipython-input-3-d2a869113561>:30: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-d2a869113561>:60: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Iter:0 Loss:4356.603 Accuracy:0.24,0.24,0.28,0.20  Learning_rate:0.0010\n",
      "Iter:20 Loss:2.306 Accuracy:0.20,0.08,0.12,0.04  Learning_rate:0.0010\n",
      "Iter:40 Loss:2.310 Accuracy:0.04,0.12,0.04,0.04  Learning_rate:0.0010\n",
      "Iter:60 Loss:2.307 Accuracy:0.00,0.00,0.08,0.12  Learning_rate:0.0010\n",
      "Iter:80 Loss:2.300 Accuracy:0.12,0.08,0.16,0.16  Learning_rate:0.0010\n",
      "Iter:100 Loss:2.297 Accuracy:0.16,0.20,0.12,0.08  Learning_rate:0.0010\n",
      "Iter:120 Loss:2.295 Accuracy:0.04,0.12,0.16,0.04  Learning_rate:0.0010\n",
      "Iter:140 Loss:2.303 Accuracy:0.08,0.08,0.08,0.12  Learning_rate:0.0010\n",
      "Iter:160 Loss:2.307 Accuracy:0.08,0.00,0.20,0.08  Learning_rate:0.0010\n",
      "Iter:180 Loss:2.313 Accuracy:0.04,0.08,0.08,0.08  Learning_rate:0.0010\n",
      "Iter:200 Loss:2.300 Accuracy:0.12,0.24,0.00,0.04  Learning_rate:0.0010\n",
      "Iter:220 Loss:2.296 Accuracy:0.08,0.24,0.12,0.08  Learning_rate:0.0010\n",
      "Iter:240 Loss:2.292 Accuracy:0.08,0.20,0.24,0.12  Learning_rate:0.0010\n",
      "Iter:260 Loss:2.302 Accuracy:0.04,0.16,0.00,0.04  Learning_rate:0.0010\n",
      "Iter:280 Loss:2.291 Accuracy:0.12,0.20,0.08,0.16  Learning_rate:0.0010\n",
      "Iter:300 Loss:2.303 Accuracy:0.08,0.08,0.04,0.04  Learning_rate:0.0010\n",
      "Iter:320 Loss:2.312 Accuracy:0.04,0.12,0.12,0.04  Learning_rate:0.0010\n",
      "Iter:340 Loss:2.306 Accuracy:0.00,0.16,0.08,0.12  Learning_rate:0.0010\n",
      "Iter:360 Loss:2.273 Accuracy:0.08,0.28,0.04,0.20  Learning_rate:0.0010\n",
      "Iter:380 Loss:2.319 Accuracy:0.12,0.12,0.08,0.08  Learning_rate:0.0010\n",
      "Iter:400 Loss:2.308 Accuracy:0.12,0.08,0.08,0.12  Learning_rate:0.0010\n",
      "Iter:420 Loss:2.297 Accuracy:0.16,0.00,0.12,0.12  Learning_rate:0.0010\n",
      "Iter:440 Loss:2.295 Accuracy:0.12,0.16,0.04,0.12  Learning_rate:0.0010\n",
      "Iter:460 Loss:2.315 Accuracy:0.04,0.12,0.12,0.04  Learning_rate:0.0010\n",
      "Iter:480 Loss:2.232 Accuracy:0.16,0.16,0.08,0.28  Learning_rate:0.0010\n",
      "Iter:500 Loss:2.264 Accuracy:0.16,0.16,0.24,0.16  Learning_rate:0.0010\n",
      "Iter:520 Loss:2.229 Accuracy:0.08,0.20,0.20,0.16  Learning_rate:0.0010\n",
      "Iter:540 Loss:2.257 Accuracy:0.04,0.20,0.16,0.24  Learning_rate:0.0010\n",
      "Iter:560 Loss:2.213 Accuracy:0.20,0.16,0.12,0.08  Learning_rate:0.0010\n",
      "Iter:580 Loss:2.250 Accuracy:0.16,0.16,0.20,0.24  Learning_rate:0.0010\n",
      "Iter:600 Loss:2.187 Accuracy:0.12,0.12,0.16,0.24  Learning_rate:0.0010\n",
      "Iter:620 Loss:2.247 Accuracy:0.12,0.08,0.24,0.20  Learning_rate:0.0010\n",
      "Iter:640 Loss:2.161 Accuracy:0.16,0.16,0.40,0.16  Learning_rate:0.0010\n",
      "Iter:660 Loss:2.074 Accuracy:0.20,0.08,0.16,0.28  Learning_rate:0.0010\n",
      "Iter:680 Loss:1.906 Accuracy:0.24,0.32,0.20,0.36  Learning_rate:0.0010\n",
      "Iter:700 Loss:2.088 Accuracy:0.20,0.32,0.24,0.20  Learning_rate:0.0010\n",
      "Iter:720 Loss:2.052 Accuracy:0.32,0.16,0.24,0.16  Learning_rate:0.0010\n",
      "Iter:740 Loss:2.081 Accuracy:0.40,0.28,0.12,0.20  Learning_rate:0.0010\n",
      "Iter:760 Loss:2.029 Accuracy:0.40,0.24,0.28,0.20  Learning_rate:0.0010\n",
      "Iter:780 Loss:1.916 Accuracy:0.32,0.24,0.32,0.16  Learning_rate:0.0010\n",
      "Iter:800 Loss:1.929 Accuracy:0.32,0.20,0.32,0.20  Learning_rate:0.0010\n",
      "Iter:820 Loss:1.977 Accuracy:0.36,0.20,0.20,0.28  Learning_rate:0.0010\n",
      "Iter:840 Loss:1.922 Accuracy:0.40,0.20,0.24,0.32  Learning_rate:0.0010\n",
      "Iter:860 Loss:1.828 Accuracy:0.36,0.28,0.32,0.40  Learning_rate:0.0010\n",
      "Iter:880 Loss:1.826 Accuracy:0.36,0.12,0.16,0.56  Learning_rate:0.0010\n",
      "Iter:900 Loss:1.631 Accuracy:0.64,0.36,0.44,0.36  Learning_rate:0.0010\n",
      "Iter:920 Loss:1.675 Accuracy:0.44,0.24,0.24,0.36  Learning_rate:0.0010\n",
      "Iter:940 Loss:1.854 Accuracy:0.28,0.24,0.36,0.32  Learning_rate:0.0010\n",
      "Iter:960 Loss:1.693 Accuracy:0.56,0.32,0.32,0.56  Learning_rate:0.0010\n",
      "Iter:980 Loss:1.628 Accuracy:0.60,0.36,0.40,0.28  Learning_rate:0.0010\n",
      "Iter:1000 Loss:1.602 Accuracy:0.68,0.32,0.20,0.40  Learning_rate:0.0010\n",
      "Iter:1020 Loss:1.396 Accuracy:0.52,0.36,0.56,0.52  Learning_rate:0.0010\n",
      "Iter:1040 Loss:1.428 Accuracy:0.68,0.32,0.28,0.64  Learning_rate:0.0010\n",
      "Iter:1060 Loss:1.643 Accuracy:0.44,0.32,0.16,0.28  Learning_rate:0.0010\n",
      "Iter:1080 Loss:1.731 Accuracy:0.48,0.12,0.32,0.44  Learning_rate:0.0010\n",
      "Iter:1100 Loss:1.324 Accuracy:0.68,0.40,0.40,0.56  Learning_rate:0.0010\n",
      "Iter:1120 Loss:1.533 Accuracy:0.68,0.44,0.20,0.36  Learning_rate:0.0010\n",
      "Iter:1140 Loss:1.276 Accuracy:0.76,0.48,0.48,0.64  Learning_rate:0.0010\n",
      "Iter:1160 Loss:1.226 Accuracy:0.68,0.48,0.52,0.52  Learning_rate:0.0010\n",
      "Iter:1180 Loss:1.191 Accuracy:0.60,0.52,0.60,0.60  Learning_rate:0.0010\n",
      "Iter:1200 Loss:1.143 Accuracy:0.72,0.48,0.48,0.72  Learning_rate:0.0010\n",
      "Iter:1220 Loss:1.096 Accuracy:0.64,0.52,0.60,0.56  Learning_rate:0.0010\n",
      "Iter:1240 Loss:1.116 Accuracy:0.84,0.48,0.44,0.72  Learning_rate:0.0010\n",
      "Iter:1260 Loss:1.177 Accuracy:0.64,0.48,0.40,0.72  Learning_rate:0.0010\n",
      "Iter:1280 Loss:1.129 Accuracy:0.52,0.60,0.48,0.80  Learning_rate:0.0010\n",
      "Iter:1300 Loss:1.179 Accuracy:0.68,0.52,0.52,0.68  Learning_rate:0.0010\n",
      "Iter:1320 Loss:1.489 Accuracy:0.52,0.24,0.36,0.52  Learning_rate:0.0010\n",
      "Iter:1340 Loss:1.147 Accuracy:0.64,0.52,0.44,0.68  Learning_rate:0.0010\n",
      "Iter:1360 Loss:0.986 Accuracy:0.76,0.56,0.40,0.80  Learning_rate:0.0010\n",
      "Iter:1380 Loss:1.198 Accuracy:0.72,0.36,0.48,0.60  Learning_rate:0.0010\n",
      "Iter:1400 Loss:1.113 Accuracy:0.80,0.60,0.48,0.60  Learning_rate:0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:1420 Loss:1.007 Accuracy:0.76,0.64,0.60,0.68  Learning_rate:0.0010\n",
      "Iter:1440 Loss:1.135 Accuracy:0.72,0.40,0.48,0.60  Learning_rate:0.0010\n",
      "Iter:1460 Loss:1.220 Accuracy:0.56,0.56,0.48,0.64  Learning_rate:0.0010\n",
      "Iter:1480 Loss:0.907 Accuracy:0.76,0.48,0.44,0.84  Learning_rate:0.0010\n",
      "Iter:1500 Loss:0.914 Accuracy:0.72,0.60,0.60,0.76  Learning_rate:0.0010\n",
      "Iter:1520 Loss:1.109 Accuracy:0.80,0.52,0.48,0.64  Learning_rate:0.0010\n",
      "Iter:1540 Loss:1.006 Accuracy:0.72,0.60,0.88,0.64  Learning_rate:0.0010\n",
      "Iter:1560 Loss:0.864 Accuracy:0.76,0.64,0.76,0.72  Learning_rate:0.0010\n",
      "Iter:1580 Loss:0.967 Accuracy:0.72,0.60,0.48,0.80  Learning_rate:0.0010\n",
      "Iter:1600 Loss:0.807 Accuracy:0.76,0.64,0.68,0.64  Learning_rate:0.0010\n",
      "Iter:1620 Loss:0.862 Accuracy:0.68,0.56,0.72,0.64  Learning_rate:0.0010\n",
      "Iter:1640 Loss:0.815 Accuracy:0.68,0.64,0.64,0.76  Learning_rate:0.0010\n",
      "Iter:1660 Loss:0.771 Accuracy:0.80,0.68,0.68,0.68  Learning_rate:0.0010\n",
      "Iter:1680 Loss:0.684 Accuracy:0.88,0.72,0.68,0.80  Learning_rate:0.0010\n",
      "Iter:1700 Loss:0.891 Accuracy:0.76,0.48,0.64,0.80  Learning_rate:0.0010\n",
      "Iter:1720 Loss:0.627 Accuracy:0.76,0.68,0.76,0.84  Learning_rate:0.0010\n",
      "Iter:1740 Loss:1.006 Accuracy:0.92,0.72,0.68,0.44  Learning_rate:0.0010\n",
      "Iter:1760 Loss:0.845 Accuracy:0.92,0.76,0.60,0.68  Learning_rate:0.0010\n",
      "Iter:1780 Loss:0.807 Accuracy:0.84,0.76,0.76,0.64  Learning_rate:0.0010\n",
      "Iter:1800 Loss:0.661 Accuracy:0.92,0.60,0.64,0.84  Learning_rate:0.0010\n",
      "Iter:1820 Loss:0.794 Accuracy:0.84,0.72,0.44,0.88  Learning_rate:0.0010\n",
      "Iter:1840 Loss:0.991 Accuracy:0.72,0.60,0.60,0.84  Learning_rate:0.0010\n",
      "Iter:1860 Loss:0.821 Accuracy:0.76,0.68,0.40,0.92  Learning_rate:0.0010\n",
      "Iter:1880 Loss:0.652 Accuracy:0.80,0.84,0.76,0.68  Learning_rate:0.0010\n",
      "Iter:1900 Loss:0.777 Accuracy:0.88,0.60,0.64,0.72  Learning_rate:0.0010\n",
      "Iter:1920 Loss:0.548 Accuracy:0.80,0.84,0.76,0.80  Learning_rate:0.0010\n",
      "Iter:1940 Loss:0.607 Accuracy:0.88,0.80,0.64,0.84  Learning_rate:0.0010\n",
      "Iter:1960 Loss:0.590 Accuracy:0.72,0.84,0.88,0.80  Learning_rate:0.0010\n",
      "Iter:1980 Loss:0.732 Accuracy:0.76,0.68,0.80,0.60  Learning_rate:0.0010\n",
      "Iter:2000 Loss:0.672 Accuracy:0.84,0.64,0.68,0.68  Learning_rate:0.0003\n",
      "Iter:2020 Loss:0.609 Accuracy:0.84,0.84,0.72,0.80  Learning_rate:0.0003\n",
      "Iter:2040 Loss:0.563 Accuracy:0.92,0.72,0.72,0.84  Learning_rate:0.0003\n",
      "Iter:2060 Loss:0.424 Accuracy:0.96,0.76,0.72,0.84  Learning_rate:0.0003\n",
      "Iter:2080 Loss:0.547 Accuracy:0.92,0.72,0.72,1.00  Learning_rate:0.0003\n",
      "Iter:2100 Loss:0.418 Accuracy:0.84,0.84,0.80,0.84  Learning_rate:0.0003\n",
      "Iter:2120 Loss:0.542 Accuracy:0.96,0.96,0.84,0.68  Learning_rate:0.0003\n",
      "Iter:2140 Loss:0.535 Accuracy:0.80,0.88,0.76,0.88  Learning_rate:0.0003\n",
      "Iter:2160 Loss:0.481 Accuracy:0.76,0.76,0.92,0.84  Learning_rate:0.0003\n",
      "Iter:2180 Loss:0.618 Accuracy:0.80,0.76,0.68,0.84  Learning_rate:0.0003\n",
      "Iter:2200 Loss:0.545 Accuracy:0.84,0.80,0.72,0.88  Learning_rate:0.0003\n",
      "Iter:2220 Loss:0.616 Accuracy:0.92,0.84,0.72,0.92  Learning_rate:0.0003\n",
      "Iter:2240 Loss:0.398 Accuracy:0.84,0.88,0.84,0.96  Learning_rate:0.0003\n",
      "Iter:2260 Loss:0.548 Accuracy:0.88,0.88,0.56,0.84  Learning_rate:0.0003\n",
      "Iter:2280 Loss:0.504 Accuracy:1.00,0.76,0.68,0.84  Learning_rate:0.0003\n",
      "Iter:2300 Loss:0.243 Accuracy:1.00,0.80,0.80,0.96  Learning_rate:0.0003\n",
      "Iter:2320 Loss:0.495 Accuracy:0.92,0.84,0.72,0.88  Learning_rate:0.0003\n",
      "Iter:2340 Loss:0.308 Accuracy:0.88,0.88,0.80,0.96  Learning_rate:0.0003\n",
      "Iter:2360 Loss:0.485 Accuracy:0.92,0.88,0.84,0.76  Learning_rate:0.0003\n",
      "Iter:2380 Loss:0.527 Accuracy:0.88,0.56,0.84,0.88  Learning_rate:0.0003\n",
      "Iter:2400 Loss:0.304 Accuracy:0.96,0.96,0.84,0.88  Learning_rate:0.0003\n",
      "Iter:2420 Loss:0.255 Accuracy:0.92,0.88,0.92,0.84  Learning_rate:0.0003\n",
      "Iter:2440 Loss:0.399 Accuracy:1.00,0.80,0.84,0.84  Learning_rate:0.0003\n",
      "Iter:2460 Loss:0.294 Accuracy:1.00,0.92,0.80,0.92  Learning_rate:0.0003\n",
      "Iter:2480 Loss:0.361 Accuracy:0.88,0.96,0.72,1.00  Learning_rate:0.0003\n",
      "Iter:2500 Loss:0.192 Accuracy:0.92,0.88,0.88,0.96  Learning_rate:0.0003\n",
      "Iter:2520 Loss:0.362 Accuracy:0.96,0.76,0.88,0.88  Learning_rate:0.0003\n",
      "Iter:2540 Loss:0.424 Accuracy:0.92,0.84,0.80,0.92  Learning_rate:0.0003\n",
      "Iter:2560 Loss:0.225 Accuracy:1.00,1.00,0.88,0.92  Learning_rate:0.0003\n",
      "Iter:2580 Loss:0.433 Accuracy:1.00,0.84,0.88,0.72  Learning_rate:0.0003\n",
      "Iter:2600 Loss:0.401 Accuracy:0.84,0.68,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:2620 Loss:0.639 Accuracy:0.92,0.84,0.80,0.84  Learning_rate:0.0003\n",
      "Iter:2640 Loss:0.302 Accuracy:0.96,0.96,0.88,0.92  Learning_rate:0.0003\n",
      "Iter:2660 Loss:0.299 Accuracy:0.96,0.88,0.92,0.84  Learning_rate:0.0003\n",
      "Iter:2680 Loss:0.432 Accuracy:0.92,0.88,0.72,0.84  Learning_rate:0.0003\n",
      "Iter:2700 Loss:0.403 Accuracy:0.92,0.76,0.84,0.88  Learning_rate:0.0003\n",
      "Iter:2720 Loss:0.198 Accuracy:0.96,0.92,0.92,0.92  Learning_rate:0.0003\n",
      "Iter:2740 Loss:0.378 Accuracy:1.00,0.92,0.96,0.84  Learning_rate:0.0003\n",
      "Iter:2760 Loss:0.379 Accuracy:0.84,0.84,0.88,0.92  Learning_rate:0.0003\n",
      "Iter:2780 Loss:0.331 Accuracy:0.88,0.84,0.96,0.96  Learning_rate:0.0003\n",
      "Iter:2800 Loss:0.220 Accuracy:1.00,0.80,0.92,1.00  Learning_rate:0.0003\n",
      "Iter:2820 Loss:0.261 Accuracy:0.96,0.92,0.88,0.88  Learning_rate:0.0003\n",
      "Iter:2840 Loss:0.337 Accuracy:0.92,0.88,0.88,0.88  Learning_rate:0.0003\n",
      "Iter:2860 Loss:0.287 Accuracy:0.96,0.84,0.96,0.84  Learning_rate:0.0003\n",
      "Iter:2880 Loss:0.422 Accuracy:0.92,0.84,0.96,0.84  Learning_rate:0.0003\n",
      "Iter:2900 Loss:0.294 Accuracy:0.96,0.96,0.72,1.00  Learning_rate:0.0003\n",
      "Iter:2920 Loss:0.354 Accuracy:0.88,0.88,0.80,0.84  Learning_rate:0.0003\n",
      "Iter:2940 Loss:0.472 Accuracy:0.92,0.84,0.76,0.88  Learning_rate:0.0003\n",
      "Iter:2960 Loss:0.525 Accuracy:0.92,0.76,0.68,0.84  Learning_rate:0.0003\n",
      "Iter:2980 Loss:0.297 Accuracy:0.92,0.92,0.84,1.00  Learning_rate:0.0003\n",
      "Iter:3000 Loss:0.172 Accuracy:0.96,0.96,0.92,0.96  Learning_rate:0.0003\n",
      "Iter:3020 Loss:0.284 Accuracy:0.96,0.88,0.80,0.88  Learning_rate:0.0003\n",
      "Iter:3040 Loss:0.372 Accuracy:0.88,0.84,0.88,0.92  Learning_rate:0.0003\n",
      "Iter:3060 Loss:0.466 Accuracy:0.84,0.84,0.80,0.88  Learning_rate:0.0003\n",
      "Iter:3080 Loss:0.282 Accuracy:0.92,0.84,0.92,0.84  Learning_rate:0.0003\n",
      "Iter:3100 Loss:0.334 Accuracy:0.84,0.96,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:3120 Loss:0.328 Accuracy:0.96,0.96,0.84,0.88  Learning_rate:0.0003\n",
      "Iter:3140 Loss:0.255 Accuracy:0.96,0.88,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:3160 Loss:0.264 Accuracy:0.84,1.00,0.88,0.92  Learning_rate:0.0003\n",
      "Iter:3180 Loss:0.247 Accuracy:0.92,0.80,0.92,0.92  Learning_rate:0.0003\n",
      "Iter:3200 Loss:0.168 Accuracy:1.00,0.92,1.00,0.96  Learning_rate:0.0003\n",
      "Iter:3220 Loss:0.190 Accuracy:0.92,0.92,1.00,0.88  Learning_rate:0.0003\n",
      "Iter:3240 Loss:0.325 Accuracy:0.84,0.72,0.96,0.88  Learning_rate:0.0003\n",
      "Iter:3260 Loss:0.270 Accuracy:0.92,0.92,0.76,0.88  Learning_rate:0.0003\n",
      "Iter:3280 Loss:0.276 Accuracy:0.88,0.84,0.96,1.00  Learning_rate:0.0003\n",
      "Iter:3300 Loss:0.192 Accuracy:0.92,0.88,0.96,1.00  Learning_rate:0.0003\n",
      "Iter:3320 Loss:0.391 Accuracy:0.92,0.84,0.80,0.92  Learning_rate:0.0003\n",
      "Iter:3340 Loss:0.333 Accuracy:0.96,0.88,0.88,0.84  Learning_rate:0.0003\n",
      "Iter:3360 Loss:0.264 Accuracy:0.92,0.88,0.84,0.96  Learning_rate:0.0003\n",
      "Iter:3380 Loss:0.193 Accuracy:0.96,0.92,0.92,0.88  Learning_rate:0.0003\n",
      "Iter:3400 Loss:0.179 Accuracy:1.00,0.96,0.88,0.92  Learning_rate:0.0003\n",
      "Iter:3420 Loss:0.238 Accuracy:0.92,0.92,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:3440 Loss:0.186 Accuracy:0.88,0.88,0.96,1.00  Learning_rate:0.0003\n",
      "Iter:3460 Loss:0.332 Accuracy:0.96,0.80,0.76,0.92  Learning_rate:0.0003\n",
      "Iter:3480 Loss:0.228 Accuracy:0.92,0.92,0.84,0.96  Learning_rate:0.0003\n",
      "Iter:3500 Loss:0.227 Accuracy:1.00,0.88,0.92,0.84  Learning_rate:0.0003\n",
      "Iter:3520 Loss:0.211 Accuracy:0.92,0.92,1.00,0.92  Learning_rate:0.0003\n",
      "Iter:3540 Loss:0.195 Accuracy:0.88,0.96,0.96,0.92  Learning_rate:0.0003\n",
      "Iter:3560 Loss:0.236 Accuracy:1.00,0.96,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:3580 Loss:0.245 Accuracy:0.92,0.80,0.92,0.96  Learning_rate:0.0003\n",
      "Iter:3600 Loss:0.360 Accuracy:0.92,0.84,0.88,0.96  Learning_rate:0.0003\n",
      "Iter:3620 Loss:0.407 Accuracy:0.96,0.76,0.92,0.88  Learning_rate:0.0003\n",
      "Iter:3640 Loss:0.275 Accuracy:0.92,0.92,0.92,0.92  Learning_rate:0.0003\n",
      "Iter:3660 Loss:0.238 Accuracy:0.96,0.80,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:3680 Loss:0.306 Accuracy:0.96,0.92,0.88,0.96  Learning_rate:0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:3700 Loss:0.317 Accuracy:1.00,0.88,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:3720 Loss:0.244 Accuracy:0.92,0.92,0.92,0.92  Learning_rate:0.0003\n",
      "Iter:3740 Loss:0.231 Accuracy:0.88,0.96,0.88,0.96  Learning_rate:0.0003\n",
      "Iter:3760 Loss:0.249 Accuracy:0.96,0.80,0.88,0.88  Learning_rate:0.0003\n",
      "Iter:3780 Loss:0.411 Accuracy:0.88,0.60,0.92,0.96  Learning_rate:0.0003\n",
      "Iter:3800 Loss:0.268 Accuracy:0.96,0.88,0.88,1.00  Learning_rate:0.0003\n",
      "Iter:3820 Loss:0.235 Accuracy:0.88,0.92,0.88,1.00  Learning_rate:0.0003\n",
      "Iter:3840 Loss:0.146 Accuracy:1.00,1.00,0.92,0.92  Learning_rate:0.0003\n",
      "Iter:3860 Loss:0.337 Accuracy:0.96,0.80,0.80,1.00  Learning_rate:0.0003\n",
      "Iter:3880 Loss:0.214 Accuracy:1.00,0.84,0.96,0.92  Learning_rate:0.0003\n",
      "Iter:3900 Loss:0.177 Accuracy:0.92,0.88,1.00,0.96  Learning_rate:0.0003\n",
      "Iter:3920 Loss:0.365 Accuracy:0.88,0.88,0.84,0.92  Learning_rate:0.0003\n",
      "Iter:3940 Loss:0.201 Accuracy:0.96,0.92,0.88,0.96  Learning_rate:0.0003\n",
      "Iter:3960 Loss:0.154 Accuracy:0.96,0.92,0.96,0.92  Learning_rate:0.0003\n",
      "Iter:3980 Loss:0.139 Accuracy:1.00,0.92,1.00,0.92  Learning_rate:0.0003\n",
      "Iter:4000 Loss:0.293 Accuracy:1.00,0.88,0.84,0.80  Learning_rate:0.0001\n",
      "Iter:4020 Loss:0.204 Accuracy:0.88,0.92,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:4040 Loss:0.195 Accuracy:1.00,1.00,0.80,0.92  Learning_rate:0.0001\n",
      "Iter:4060 Loss:0.169 Accuracy:1.00,0.84,0.92,0.96  Learning_rate:0.0001\n",
      "Iter:4080 Loss:0.134 Accuracy:0.92,0.96,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:4100 Loss:0.183 Accuracy:0.92,0.92,0.88,0.96  Learning_rate:0.0001\n",
      "Iter:4120 Loss:0.177 Accuracy:0.96,0.96,1.00,0.92  Learning_rate:0.0001\n",
      "Iter:4140 Loss:0.281 Accuracy:1.00,0.88,0.76,0.96  Learning_rate:0.0001\n",
      "Iter:4160 Loss:0.289 Accuracy:0.96,0.92,0.84,0.88  Learning_rate:0.0001\n",
      "Iter:4180 Loss:0.169 Accuracy:0.96,0.88,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:4200 Loss:0.165 Accuracy:0.96,0.88,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:4220 Loss:0.160 Accuracy:0.88,0.88,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:4240 Loss:0.272 Accuracy:0.88,0.92,0.92,0.92  Learning_rate:0.0001\n",
      "Iter:4260 Loss:0.201 Accuracy:0.92,0.88,0.88,0.96  Learning_rate:0.0001\n",
      "Iter:4280 Loss:0.264 Accuracy:1.00,0.84,0.92,0.84  Learning_rate:0.0001\n",
      "Iter:4300 Loss:0.186 Accuracy:1.00,0.96,0.80,0.96  Learning_rate:0.0001\n",
      "Iter:4320 Loss:0.149 Accuracy:0.92,0.96,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:4340 Loss:0.291 Accuracy:1.00,0.92,0.80,0.88  Learning_rate:0.0001\n",
      "Iter:4360 Loss:0.107 Accuracy:1.00,0.96,1.00,0.84  Learning_rate:0.0001\n",
      "Iter:4380 Loss:0.244 Accuracy:0.92,0.96,0.92,0.92  Learning_rate:0.0001\n",
      "Iter:4400 Loss:0.176 Accuracy:1.00,0.92,0.96,0.92  Learning_rate:0.0001\n",
      "Iter:4420 Loss:0.150 Accuracy:0.88,0.88,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:4440 Loss:0.144 Accuracy:0.96,0.96,1.00,0.88  Learning_rate:0.0001\n",
      "Iter:4460 Loss:0.174 Accuracy:0.96,0.88,0.96,0.92  Learning_rate:0.0001\n",
      "Iter:4480 Loss:0.144 Accuracy:0.96,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:4500 Loss:0.233 Accuracy:0.92,0.92,0.92,0.92  Learning_rate:0.0001\n",
      "Iter:4520 Loss:0.162 Accuracy:1.00,0.96,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:4540 Loss:0.192 Accuracy:0.92,1.00,0.88,0.88  Learning_rate:0.0001\n",
      "Iter:4560 Loss:0.180 Accuracy:1.00,0.92,0.96,0.92  Learning_rate:0.0001\n",
      "Iter:4580 Loss:0.140 Accuracy:0.96,0.92,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:4600 Loss:0.248 Accuracy:0.88,0.88,0.80,1.00  Learning_rate:0.0001\n",
      "Iter:4620 Loss:0.122 Accuracy:1.00,0.96,1.00,0.88  Learning_rate:0.0001\n",
      "Iter:4640 Loss:0.183 Accuracy:0.96,0.96,0.88,0.92  Learning_rate:0.0001\n",
      "Iter:4660 Loss:0.187 Accuracy:0.96,0.92,0.92,0.96  Learning_rate:0.0001\n",
      "Iter:4680 Loss:0.064 Accuracy:1.00,1.00,1.00,1.00  Learning_rate:0.0001\n",
      "Iter:4700 Loss:0.245 Accuracy:0.88,0.96,0.84,0.96  Learning_rate:0.0001\n",
      "Iter:4720 Loss:0.161 Accuracy:0.92,0.96,0.92,0.96  Learning_rate:0.0001\n",
      "Iter:4740 Loss:0.129 Accuracy:0.96,0.96,1.00,0.96  Learning_rate:0.0001\n",
      "Iter:4760 Loss:0.146 Accuracy:1.00,0.88,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:4780 Loss:0.127 Accuracy:0.96,0.92,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:4800 Loss:0.218 Accuracy:1.00,0.96,0.84,0.92  Learning_rate:0.0001\n",
      "Iter:4820 Loss:0.103 Accuracy:0.96,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:4840 Loss:0.179 Accuracy:0.84,0.92,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:4860 Loss:0.098 Accuracy:1.00,0.96,1.00,0.96  Learning_rate:0.0001\n",
      "Iter:4880 Loss:0.153 Accuracy:1.00,0.96,0.92,0.96  Learning_rate:0.0001\n",
      "Iter:4900 Loss:0.036 Accuracy:1.00,1.00,1.00,0.96  Learning_rate:0.0001\n",
      "Iter:4920 Loss:0.121 Accuracy:0.96,0.96,1.00,0.88  Learning_rate:0.0001\n",
      "Iter:4940 Loss:0.120 Accuracy:0.96,0.96,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:4960 Loss:0.230 Accuracy:0.96,0.96,0.84,0.92  Learning_rate:0.0001\n",
      "Iter:4980 Loss:0.129 Accuracy:1.00,0.92,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5000 Loss:0.069 Accuracy:1.00,0.96,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5020 Loss:0.039 Accuracy:1.00,1.00,1.00,1.00  Learning_rate:0.0001\n",
      "Iter:5040 Loss:0.158 Accuracy:1.00,0.96,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:5060 Loss:0.139 Accuracy:0.92,0.88,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5080 Loss:0.156 Accuracy:0.96,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5100 Loss:0.106 Accuracy:1.00,0.88,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5120 Loss:0.146 Accuracy:1.00,0.92,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:5140 Loss:0.165 Accuracy:0.96,0.96,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5160 Loss:0.157 Accuracy:0.88,1.00,0.96,0.92  Learning_rate:0.0001\n",
      "Iter:5180 Loss:0.189 Accuracy:0.92,0.92,0.84,0.92  Learning_rate:0.0001\n",
      "Iter:5200 Loss:0.093 Accuracy:1.00,0.92,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5220 Loss:0.127 Accuracy:0.92,0.96,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5240 Loss:0.066 Accuracy:0.96,1.00,1.00,1.00  Learning_rate:0.0001\n",
      "Iter:5260 Loss:0.107 Accuracy:0.92,1.00,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5280 Loss:0.199 Accuracy:0.88,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5300 Loss:0.109 Accuracy:1.00,0.96,0.96,0.92  Learning_rate:0.0001\n",
      "Iter:5320 Loss:0.087 Accuracy:0.96,1.00,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5340 Loss:0.083 Accuracy:1.00,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5360 Loss:0.100 Accuracy:1.00,0.92,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5380 Loss:0.087 Accuracy:1.00,0.96,1.00,1.00  Learning_rate:0.0001\n",
      "Iter:5400 Loss:0.208 Accuracy:0.92,0.88,0.92,0.92  Learning_rate:0.0001\n",
      "Iter:5420 Loss:0.097 Accuracy:0.96,1.00,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5440 Loss:0.195 Accuracy:1.00,0.92,0.88,0.96  Learning_rate:0.0001\n",
      "Iter:5460 Loss:0.160 Accuracy:1.00,0.88,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:5480 Loss:0.107 Accuracy:1.00,1.00,0.92,0.92  Learning_rate:0.0001\n",
      "Iter:5500 Loss:0.158 Accuracy:0.92,1.00,1.00,0.96  Learning_rate:0.0001\n",
      "Iter:5520 Loss:0.095 Accuracy:0.96,0.92,1.00,1.00  Learning_rate:0.0001\n",
      "Iter:5540 Loss:0.141 Accuracy:1.00,0.88,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5560 Loss:0.241 Accuracy:0.96,0.88,0.92,0.84  Learning_rate:0.0001\n",
      "Iter:5580 Loss:0.159 Accuracy:1.00,0.92,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:5600 Loss:0.232 Accuracy:0.96,0.96,0.92,0.96  Learning_rate:0.0001\n",
      "Iter:5620 Loss:0.095 Accuracy:1.00,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5640 Loss:0.240 Accuracy:0.96,0.88,0.84,0.92  Learning_rate:0.0001\n",
      "Iter:5660 Loss:0.082 Accuracy:1.00,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5680 Loss:0.068 Accuracy:1.00,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5700 Loss:0.123 Accuracy:0.92,0.96,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5720 Loss:0.125 Accuracy:1.00,1.00,0.96,0.88  Learning_rate:0.0001\n",
      "Iter:5740 Loss:0.269 Accuracy:0.92,0.88,0.88,0.92  Learning_rate:0.0001\n",
      "Iter:5760 Loss:0.096 Accuracy:1.00,0.92,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5780 Loss:0.133 Accuracy:1.00,0.96,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5800 Loss:0.126 Accuracy:0.92,0.88,1.00,0.92  Learning_rate:0.0001\n",
      "Iter:5820 Loss:0.095 Accuracy:1.00,0.92,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5840 Loss:0.081 Accuracy:1.00,1.00,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5860 Loss:0.142 Accuracy:1.00,0.96,0.88,1.00  Learning_rate:0.0001\n",
      "Iter:5880 Loss:0.088 Accuracy:0.96,0.96,0.84,1.00  Learning_rate:0.0001\n",
      "Iter:5900 Loss:0.144 Accuracy:0.96,0.92,0.96,0.96  Learning_rate:0.0001\n",
      "Iter:5920 Loss:0.149 Accuracy:0.92,0.96,0.92,1.00  Learning_rate:0.0001\n",
      "Iter:5940 Loss:0.130 Accuracy:1.00,0.84,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:5960 Loss:0.075 Accuracy:1.00,0.96,1.00,0.96  Learning_rate:0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:5980 Loss:0.153 Accuracy:0.92,0.92,0.96,1.00  Learning_rate:0.0001\n",
      "Iter:6000 Loss:0.096 Accuracy:1.00,0.96,1.00,0.96  Learning_rate:0.0000\n"
     ]
    }
   ],
   "source": [
    "# 获取图片数据和标签\n",
    "image, label0, label1, label2, label3 = read_and_decode(TFRECORD_FILE)\n",
    "\n",
    "#使用shuffle_batch可以随机打乱\n",
    "image_batch, label_batch0, label_batch1, label_batch2, label_batch3 = tf.train.shuffle_batch(\n",
    "        [image, label0, label1, label2, label3], batch_size = BATCH_SIZE,\n",
    "        capacity = 50000, min_after_dequeue=10000, num_threads=1)\n",
    "\n",
    "#定义网络结构\n",
    "train_network_fn = nets_factory.get_network_fn(\n",
    "    'alexnet_v2',\n",
    "    num_classes=CHAR_SET_LEN,\n",
    "    weight_decay=0.0005,\n",
    "    is_training=True)\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    # inputs: a tensor of size [batch_size, height, width, channels]\n",
    "    X = tf.reshape(x, [BATCH_SIZE, 224, 224, 1])\n",
    "    # 数据输入网络得到输出值\n",
    "    logits0,logits1,logits2,logits3,end_points = train_network_fn(X)\n",
    "    \n",
    "    # 把标签转成one_hot的形式\n",
    "    one_hot_labels0 = tf.one_hot(indices=tf.cast(y0, tf.int32), depth=CHAR_SET_LEN)\n",
    "    one_hot_labels1 = tf.one_hot(indices=tf.cast(y1, tf.int32), depth=CHAR_SET_LEN)\n",
    "    one_hot_labels2 = tf.one_hot(indices=tf.cast(y2, tf.int32), depth=CHAR_SET_LEN)\n",
    "    one_hot_labels3 = tf.one_hot(indices=tf.cast(y3, tf.int32), depth=CHAR_SET_LEN)\n",
    "    \n",
    "    # 计算loss\n",
    "    loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits0,labels=one_hot_labels0)) \n",
    "    loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits1,labels=one_hot_labels1)) \n",
    "    loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits2,labels=one_hot_labels2)) \n",
    "    loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits3,labels=one_hot_labels3)) \n",
    "    # 计算总的loss\n",
    "    total_loss = (loss0+loss1+loss2+loss3)/4.0\n",
    "    # 优化total_loss\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss) \n",
    "    \n",
    "    # 计算准确率\n",
    "    correct_prediction0 = tf.equal(tf.argmax(one_hot_labels0,1),tf.argmax(logits0,1))\n",
    "    accuracy0 = tf.reduce_mean(tf.cast(correct_prediction0,tf.float32))\n",
    "    \n",
    "    correct_prediction1 = tf.equal(tf.argmax(one_hot_labels1,1),tf.argmax(logits1,1))\n",
    "    accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1,tf.float32))\n",
    "    \n",
    "    correct_prediction2 = tf.equal(tf.argmax(one_hot_labels2,1),tf.argmax(logits2,1))\n",
    "    accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2,tf.float32))\n",
    "    \n",
    "    correct_prediction3 = tf.equal(tf.argmax(one_hot_labels3,1),tf.argmax(logits3,1))\n",
    "    accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3,tf.float32)) \n",
    "    \n",
    "    # 用于保存模型\n",
    "    saver = tf.train.Saver()\n",
    "    # 初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 创建一个协调器，管理线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    #启动QueueRunner 此时文件名队列已进队\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for i in range(6001):\n",
    "        # 获取一个批次的数据和标签\n",
    "        b_image, b_label0, b_label1 ,b_label2 ,b_label3 = sess.run([image_batch, label_batch0, label_batch1, label_batch2, label_batch3])\n",
    "        # 优化模型\n",
    "        sess.run(optimizer, feed_dict={x: b_image, y0:b_label0, y1: b_label1, y2: b_label2, y3: b_label3})  \n",
    "        \n",
    "        #每迭代20次计算一次loss和准确率\n",
    "        if i % 20 == 0:\n",
    "            #每迭代2000次降低一次学习率\n",
    "            if i % 2000 == 0:\n",
    "                sess.run(tf.assign(lr, lr/3))\n",
    "            acc0,acc1,acc2,acc3,loss_ = sess.run([accuracy0,accuracy1,accuracy2,accuracy3,total_loss],feed_dict={x: b_image,\n",
    "                                                                                                                y0: b_label0,\n",
    "                                                                                                                y1: b_label1,\n",
    "                                                                                                                y2: b_label2,\n",
    "                                                                                                                y3: b_label3})\n",
    "            learning_rate = sess.run(lr)\n",
    "            print(\"Iter:%d Loss:%.3f Accuracy:%.2f,%.2f,%.2f,%.2f  Learning_rate:%.4f\" % (i, loss_, acc0,acc1,acc2,acc3,learning_rate))\n",
    "            \n",
    "            if i == 6000:\n",
    "                saver.save(sess, \"model/captcha_model/crack_captcha.model\", global_step = i)\n",
    "                break\n",
    "    # 通知其他线程关闭\n",
    "    coord.request_stop()\n",
    "    # 其他所有线程关闭之后，这一函数才能返回\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
