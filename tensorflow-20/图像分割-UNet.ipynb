{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import itertools\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.ArgumentParser().add_argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_width,\n",
    "        input_height,\n",
    "        num_classes,\n",
    "        train_images,\n",
    "        train_instances,\n",
    "        val_images,\n",
    "        val_instances,\n",
    "        ecophs,\n",
    "        lr,\n",
    "        lr_decay,\n",
    "        batch_size,\n",
    "        save_path\n",
    "    ):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.num_classes = num_classes\n",
    "        self.train_images = train_images\n",
    "        self.train_instances = train_instances\n",
    "        self.val_images = val_images\n",
    "        self.val_instances = val_instances\n",
    "        self.ecophs = ecophs\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def lefNetwork(self, inputs):\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(inputs)\n",
    "        o_1 = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(o_1)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_2 = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(o_2)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(256, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_3 = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(o_3)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_4 = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(o_4)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(1024, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_5 = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "\n",
    "        return [o_1, o_2, o_3, o_4, o_5]\n",
    "    \n",
    "    def rightNetwork(self, inputs):\n",
    "        c_1, c_2, c_3, c_4, o_5 = inputs\n",
    "        \n",
    "        o_5 = tf.keras.layers.UpSampling2D((2, 2))(o_5)\n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(4)(c_4), o_5], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(16)(c_3), x], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(256, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(256, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "        \n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(40)(c_2), x], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "        \n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(88)(c_1), x], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(self.num_classes, (1, 1), padding='valid')(x)\n",
    "        x = tf.keras.layers.Activation('softmax')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build_model(self):\n",
    "        inputs = tf.keras.Input(shape=[self.input_height, self.input_width, 3])\n",
    "        left_output = self.lefNetwork(inputs)\n",
    "        right_output = self.rightNetwork(left_output)\n",
    "        \n",
    "        model = tf.keras.Model(inputs = inputs, outputs = right_output)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self):\n",
    "        G_train = self.dataGenerator(mode='training')\n",
    "        G_eval = self.dataGenerator(mode='validation')\n",
    "        \n",
    "        model = self.build_model()\n",
    "        model.summary()\n",
    "        model.compile(\n",
    "            optimizer = tf.keras.optimizers.Adam(self.lr, self.lr_decay),\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics = ['categorical_accuracy', 'Recall', 'AUC']\n",
    "        )\n",
    "        model.fit_generator(G_train, 4, validation_data=G_eval, validation_steps=4, epochs=self.ecophs)\n",
    "        model.save(self.save_path)\n",
    "        \n",
    "    def dataGenerator(self, mode):\n",
    "        if mode =='training':\n",
    "            images = glob.glob(self.train_images + '*.png')\n",
    "            images.sort()\n",
    "            instances = glob.glob(self.train_instances + '*.png')\n",
    "            instances.sort()\n",
    "            zipped = itertools.cycle(zip(images, instances))\n",
    "            while True:\n",
    "                x_train = []\n",
    "                y_train = []\n",
    "                \n",
    "                for _ in range(self.batch_size):\n",
    "                    img, seg = next(zipped)\n",
    "                    img = cv2.resize(cv2.imread(img, 1), (self.input_width, self.input_height))\n",
    "                    seg = tf.keras.utils.to_categorical(cv2.imread(seg, 0), num_classes=self.num_classes)\n",
    "                        \n",
    "                    x_train.append(img)\n",
    "                    y_train.append(seg)\n",
    "                    \n",
    "                yield np.array(x_train), np.array(y_train)\n",
    "                \n",
    "        if mode =='validation':\n",
    "            images = glob.glob(self.val_images + '*.png')\n",
    "            images.sort()\n",
    "            instances = glob.glob(self.val_instances + '*.png')\n",
    "            instances.sort()\n",
    "            zipped = itertools.cycle(zip(images, instances))\n",
    "            while True:\n",
    "                x_val = []\n",
    "                y_val = []\n",
    "                \n",
    "                for _ in range(self.batch_size):\n",
    "                    img, seg = next(zipped)\n",
    "                    img = cv2.resize(cv2.imread(img, 1), (self.input_width, self.input_height))\n",
    "                    seg = tf.keras.utils.to_categorical(cv2.imread(seg, 0), num_classes=self.num_classes)\n",
    "                        \n",
    "                    x_val.append(img)\n",
    "                    y_val.append(seg)\n",
    "                    \n",
    "                yield np.array(x_train), np.array(y_train)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(\n",
    "    input_width=572,\n",
    "    input_height=572,\n",
    "    num_classes=3,\n",
    "    train_images='./datasets/training/images/',\n",
    "    train_instances='./datasets/training/instances/',\n",
    "    val_images='./datasets/validation/images/',\n",
    "    val_instances='./datasets/validation/instances/',\n",
    "    ecophs=10,\n",
    "    lr=0.0001,\n",
    "    lr_decay=0.000001,\n",
    "    batch_size=2,\n",
    "    save_path='./my_models/model_unet.h5'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 572, 572, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 570, 570, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 568, 568, 64) 36928       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 284, 284, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 282, 282, 128 73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 280, 280, 64) 73792       conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 140, 140, 64) 0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 138, 138, 256 147712      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 136, 136, 64) 147520      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 68, 68, 64)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 66, 66, 512)  295424      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 64, 64)   294976      conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 30, 30, 1024) 590848      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 28, 28, 64)   589888      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_8 (Cropping2D)       (None, 56, 56, 64)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 56, 56, 64)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 56, 56, 128)  0           cropping2d_8[0][0]               \n",
      "                                                                 up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 54, 54, 512)  590336      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 52, 52, 512)  2359808     conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_9 (Cropping2D)       (None, 104, 104, 64) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 104, 104, 512 0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 104, 104, 576 0           cropping2d_9[0][0]               \n",
      "                                                                 up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 102, 102, 256 1327360     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 100, 100, 256 590080      conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_10 (Cropping2D)      (None, 200, 200, 64) 0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 200, 200, 256 0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 200, 200, 320 0           cropping2d_10[0][0]              \n",
      "                                                                 up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 198, 198, 128 368768      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 196, 196, 128 147584      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_11 (Cropping2D)      (None, 392, 392, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 392, 392, 128 0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 392, 392, 192 0           cropping2d_11[0][0]              \n",
      "                                                                 up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 390, 390, 64) 110656      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 388, 388, 64) 36928       conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 388, 388, 3)  195         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 388, 388, 3)  0           conv2d_56[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,784,451\n",
      "Trainable params: 7,784,451\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet.build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 572, 572, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 570, 570, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 568, 568, 64) 36928       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 284, 284, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 282, 282, 128 73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 280, 280, 64) 73792       conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 140, 140, 64) 0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 138, 138, 256 147712      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 136, 136, 64) 147520      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 68, 68, 64)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 66, 66, 512)  295424      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 64, 64)   294976      conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 30, 30, 1024) 590848      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 28, 28, 64)   589888      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_8 (Cropping2D)       (None, 56, 56, 64)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 56, 56, 64)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 56, 56, 128)  0           cropping2d_8[0][0]               \n",
      "                                                                 up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 54, 54, 512)  590336      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 52, 52, 512)  2359808     conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_9 (Cropping2D)       (None, 104, 104, 64) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 104, 104, 512 0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 104, 104, 576 0           cropping2d_9[0][0]               \n",
      "                                                                 up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 102, 102, 256 1327360     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 100, 100, 256 590080      conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_10 (Cropping2D)      (None, 200, 200, 64) 0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 200, 200, 256 0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 200, 200, 320 0           cropping2d_10[0][0]              \n",
      "                                                                 up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 198, 198, 128 368768      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 196, 196, 128 147584      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_11 (Cropping2D)      (None, 392, 392, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 392, 392, 128 0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 392, 392, 192 0           cropping2d_11[0][0]              \n",
      "                                                                 up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 390, 390, 64) 110656      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 388, 388, 64) 36928       conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 388, 388, 3)  195         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 388, 388, 3)  0           conv2d_56[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,784,451\n",
      "Trainable params: 7,784,451\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "unet.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in glob.glob('./datasets/trainging/instances/' + '*.png'):\n",
    "    img_name = os.path.split(item)[1].split('.p')[0]\n",
    "    \n",
    "    img = cv2.imread(item, 0)\n",
    "    img = cv2.resize(img, (388, 388))\n",
    "    \n",
    "#     np.unique(img)\n",
    "    img[img==38] = 1\n",
    "    img[img==75] = 2\n",
    "    \n",
    "    os.remove(item)\n",
    "    cv2.imwrite(item, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 查看instances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./datasets/training/instances/label4.png', 0)\n",
    "# img = cv2.imread('E:/download/dataset/palnts/label/0.jpg', 0)\n",
    "np.unique(img)\n",
    "# cv2.imshow(img)\n",
    "# print(img)\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load('./snapshots/model_unet.h5')\n",
    "for i in range(10):\n",
    "    img = cv2.resize(cv2.imread('datasets/validation/images/' + str(i) + '.jpg'), (572,572))/ 255.0\n",
    "    img = np.expand_dims(img, 0)\n",
    "    \n",
    "    pred = model.predict(img)\n",
    "    pred = np.argmax(pred[0], axis=-1)\n",
    "    \n",
    "    plt.imshow(pred)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20",
   "language": "python",
   "name": "tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
